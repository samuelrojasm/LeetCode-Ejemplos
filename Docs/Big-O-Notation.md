# ğŸ“ˆ Big-O Notation: AnÃ¡lisis de Complejidad Computacional 

Este documento (`Big-O-Notation.md`) proporciona una explicaciÃ³n detallada de la **NotaciÃ³n Big-O**, una herramienta fundamental en la informÃ¡tica utilizada para analizar la eficiencia de algoritmos en tÃ©rminos de **tiempo de ejecuciÃ³n** y **uso de memoria**.  

## ğŸ“Œ Â¿QuÃ© es la NotaciÃ³n Big-O?  
La **NotaciÃ³n Big-O** describe el **comportamiento asintÃ³tico** de un algoritmo, es decir, **cÃ³mo su rendimiento escala a medida que aumenta el tamaÃ±o de la entrada** \(n\). Nos permite comparar la eficiencia de diferentes algoritmos sin necesidad de ejecutar cÃ³digo.

ğŸ’¡ **Ejemplo:** Si un algoritmo tiene una complejidad de **O(n)**, significa que el tiempo de ejecuciÃ³n crece proporcionalmente con el tamaÃ±o de la entrada.  

---

## ğŸ“– Contenido del Documento  

âœ… **Conceptos clave** sobre la notaciÃ³n Big-O.  
âœ… **Diferentes tipos de complejidad temporal y cantidad de memoria.**  
âœ… **Ejemplos de anÃ¡lisis de algoritmos con Big-O.**  
âœ… **Casos Peor, Mejor y Promedio.**   
âœ… **Tabla de complejidades comunes y su impacto.**  
âœ… **Factores Claves para un Algoritmo Eficiente.**  
âœ… **Crecimiento de Diferentes Complejidades**  

---

## ğŸ¯ Â¿Por quÃ© es importante Big-O?  
âœ… Permite comparar algoritmos y seleccionar el mÃ¡s eficiente.  
âœ… Ayuda a evitar soluciones que se vuelven ineficientes en grandes volÃºmenes de datos.  
âœ… Es fundamental en entrevistas tÃ©cnicas de programaciÃ³n.  

---

## âš¡ Complejidades Comunes en Big-O  

| NotaciÃ³n | Nombre | Ejemplo |
|----------|-------------------|--------------------|
| **O(1)** | Tiempo constante | Acceder a un elemento en un array |
| **O(log n)** | Tiempo logarÃ­tmico | BÃºsqueda binaria |
| **O(n)** | Tiempo lineal | Recorrer un array |
| **O(n log n)** | Tiempo casi lineal | MergeSort, QuickSort (mejor caso) |
| **O(nÂ²)** | Tiempo cuadrÃ¡tico | Algoritmo de burbuja, bucles anidados |
| **O(2â¿)** | Tiempo exponencial | Algoritmos de backtracking (ej. N-Reinas) |
| **O(n!)** | Tiempo factorial | Algoritmo de fuerza bruta en permutaciones, Problema del viajero (TSP) |

ğŸ“Œ **Mientras menor sea la complejidad, mÃ¡s eficiente serÃ¡ el algoritmo.**  

---

## ğŸ›  Ejemplo de AnÃ¡lisis con Big-O  

**Ejemplo 1: Algoritmo con O(n)** 
- Este algoritmo recorre ğ‘› elementos, por lo que su complejidad es O(n)
- El tiempo de ejecuciÃ³n crece proporcionalmente con el tamaÃ±o de la entrada.
```python
def print_numbers(n):
    for i in range(n):
        print(i)

# Llamar a print_numbers(5) imprimirÃ¡ 0,1,2,3,4 -> O(n)
```

**Ejemplo 2: Algoritmo con O(nÂ²)**
- Dado que hay un bucle dentro de otro, la complejidad se vuelve O(nÂ²)
```python
def print_pairs(n):
    for i in range(n):
        for j in range(n):
            print(i, j)

# Doble ciclo anidado -> O(nÂ²)
```

---

## **ğŸ“Š Tabla de Complejidades Comunes y su Impacto** 

| **NotaciÃ³n**      | **Nombre**              | **Ejemplo de Algoritmo**          | **Impacto en el Rendimiento**  |
|------------------|------------------------|----------------------------------|-------------------------------|
| **O(1)**         | Tiempo constante        | Acceder a un elemento en un array | Excelente, sin importar el tamaÃ±o del input. |
| **O(log n)**     | Tiempo logarÃ­tmico      | BÃºsqueda binaria                 | Muy eficiente incluso para grandes entradas. |
| **O(n)**         | Tiempo lineal           | BÃºsqueda en una lista no ordenada | Aceptable para tamaÃ±os moderados. |
| **O(n log n)**   | Tiempo casi lineal      | MergeSort, QuickSort (promedio)   | Bueno para ordenamiento eficiente. |
| **O(nÂ²)**        | Tiempo cuadrÃ¡tico       | Bubble Sort, Insertion Sort       | Malo para grandes volÃºmenes de datos. |
| **O(2â¿)**        | Tiempo exponencial      | RecursiÃ³n en la serie de Fibonacci | ImprÃ¡ctico para grandes `n`. |
| **O(n!)**        | Tiempo factorial        | Algoritmos de fuerza bruta en combinaciones | Extremadamente lento incluso para `n=20`. |

ğŸ“Œ **ConclusiÃ³n:**  
- **O(1), O(log n) y O(n log n)** son ideales para algoritmos eficientes.  
- **O(nÂ²), O(2â¿) y O(n!)** deben evitarse en entradas grandes.  

ğŸ” **Ejemplo prÃ¡ctico:**  
- Si tienes `n = 1,000,000`, una bÃºsqueda en **O(log n)** tomarÃ¡ alrededor de **20 operaciones**, mientras que una en **O(n)** tomarÃ¡ **1,000,000 operaciones**. Â¡Elegir bien la complejidad hace una gran diferencia! ğŸš€

---

## ğŸ“Š AnÃ¡lisis de Complejidad: Casos Peor, Mejor y Promedio  

Cuando analizamos la eficiencia de un algoritmo, es importante considerar tres escenarios distintos:  

1ï¸âƒ£ **Peor Caso (Worst Case, O)**  
2ï¸âƒ£ **Mejor Caso (Best Case, Î©)**  
3ï¸âƒ£ **Caso Promedio (Average Case, Î˜)**  

ğŸ“Œ **El Peor Caso** es el mÃ¡s Ãºtil para garantizar eficiencia. Sin embargo, el **Caso Promedio** suele reflejar mejor el rendimiento real. ğŸš€

---

### **1ï¸âƒ£ Peor Caso (Worst Case - O)**  
ğŸ”¹ Representado por **O (Big-O Notation)**  
ğŸ”¹ Es el tiempo mÃ¡ximo que tomarÃ¡ el algoritmo en ejecutarse.  
ğŸ”¹ Se usa para garantizar que un algoritmo no supere un cierto lÃ­mite de tiempo.  

#### **Ejemplo: BÃºsqueda en un arreglo desordenado (O(n))**
ğŸ“Œ **Peor caso**: Si el objetivo estÃ¡ al final de la lista o no estÃ¡ presente, se recorre toda la lista â†’ O(n)  
```python
def buscar(lista, objetivo):
    for elemento in lista:
        if elemento == objetivo:
            return True
    return False
```

---

### **2ï¸âƒ£ Mejor Caso (Best Case - Î©)**
ğŸ”¹ Representado por Î© (Omega Notation).  
ğŸ”¹ Es el tiempo mÃ­nimo que puede tomar el algoritmo en ejecutarse.  
ğŸ”¹ No siempre es Ãºtil, porque no siempre ocurre en la prÃ¡ctica.  

#### **Ejemplo: BÃºsqueda en una lista ordenada (Î©(1))**
ğŸ“Œ **Mejor caso**: Si el objetivo estÃ¡ en la primera posiciÃ³n, se encuentra en O(1).  
```python
def buscar(lista, objetivo):
    if lista[0] == objetivo:
        return True
    return buscar(lista[1:], objetivo)  # ContinÃºa la bÃºsqueda
```

---

### **3ï¸âƒ£ Caso Promedio (Average Case - Î˜)**
ğŸ”¹ Representado por Î˜ (Theta Notation)  
ğŸ”¹ Es el tiempo esperado si todas las entradas son igualmente probables.  
ğŸ”¹ Se usa en anÃ¡lisis probabilÃ­stico cuando el peor caso no siempre es realista.  

#### Ejemplo: BÃºsqueda en un arreglo desordenado
ğŸ“Œ **Caso promedio**: En una lista de tamaÃ±o n, se asume que el elemento se encuentra en la mitad â†’ O(n/2) â‰ˆ O(n).
    - Si el objetivo estÃ¡ al inicio â†’ O(1)
    - Si el objetivo estÃ¡ en el medio â†’ O(n/2)
    - Si el objetivo no estÃ¡ â†’ O(n)

---

### **ğŸ” Ejemplo con Algoritmo de Ordenamiento: QuickSort**  

| **Caso**         | **DescripciÃ³n** | **Complejidad** |
|-----------------|----------------|----------------|
| **Peor Caso (O)** | Ocurre cuando siempre elegimos el peor pivote, es decir, el elemento mÃ¡s pequeÃ±o o mÃ¡s grande, y el array estÃ¡ ordenado inversamente. | **O(nÂ²)** |
| **Mejor Caso (Î©)** | Se da cuando siempre elegimos el pivote ideal, dividiendo el array en partes iguales en cada iteraciÃ³n. | **O(n log n)** |
| **Caso Promedio (Î˜)** | En la mayorÃ­a de los casos, QuickSort se comporta de manera eficiente al dividir los elementos de forma mÃ¡s equilibrada. | **O(n log n)** |

---

### ğŸ“Š **Resumen de AnÃ¡lisis de Complejidad**  

| **Tipo de Caso**  | **NotaciÃ³n**  | **CuÃ¡ndo ocurre**  |
|------------------|-------------|------------------|
| **Peor Caso**    | **O(f(n))**  | Cuando el algoritmo tarda lo mÃ¡ximo posible en ejecutarse. |
| **Mejor Caso**   | **Î©(f(n))**  | Cuando el algoritmo se ejecuta en el menor tiempo posible. |
| **Caso Promedio** | **Î˜(f(n))**  | Tiempo esperado considerando una entrada aleatoria. |

---

## ğŸ¯ Factores Claves para un Algoritmo Eficiente

Al crear un **algoritmo eficiente** para **anÃ¡lisis de datos**, es crucial considerar los siguientes puntos para asegurarte de que cumple con los parÃ¡metros adecuados en tÃ©rminos de **tiempo** y **uso de memoria**.  

---

### **1ï¸âƒ£ Complejidad Temporal (Tiempo de EjecuciÃ³n - O(f(n)))**
ğŸ”¹ EvalÃºa el **nÃºmero de operaciones** que realiza el algoritmo en funciÃ³n del tamaÃ±o de los datos `n`.  
ğŸ”¹ Evita **complejidades ineficientes** (`O(nÂ²)`, `O(2â¿)`, `O(n!)`).  
ğŸ”¹ Prefiere estructuras eficientes como **bÃºsqueda binaria (`O(log n)`)** o **dividir y vencer (`O(n log n)`)**.  

#### **âœ” SoluciÃ³n:**
- Usa **estructuras de datos eficientes** como `set`, `dict` en Python o `HashMap` en Java.
- Prefiere algoritmos con menor crecimiento de complejidad, como **bÃºsqueda binaria** y **ordenamiento eficiente**.  

#### **Ejemplo:**
**BÃºsqueda en una lista ordenada usando bÃºsqueda binaria (O(log n)):**  
```python
def busqueda_binaria(lista, objetivo):
    bajo = 0
    alto = len(lista) - 1
    while bajo <= alto:
        medio = (bajo + alto) // 2
        if lista[medio] == objetivo:
            return medio
        elif lista[medio] < objetivo:
            bajo = medio + 1
        else:
            alto = medio - 1
    return -1
```
ğŸ“Œ **Complejidad: O(log n)**, ya que reduce el tamaÃ±o del problema a la mitad en cada iteraciÃ³n.  

---

### **2ï¸âƒ£ Complejidad Espacial (Uso de Memoria - O(f(n)))**  
ğŸ”¹ Determina cuÃ¡nto espacio adicional usa el algoritmo mÃ¡s allÃ¡ de los datos de entrada.  
ğŸ”¹ Evita estructuras innecesarias que dupliquen la memoria utilizada.  
ğŸ”¹ Ten cuidado con la recursividad profunda, ya que consume espacio en la pila de ejecuciÃ³n (stack).  

#### **âœ” SoluciÃ³n:**
- Usa iteraciones en lugar de recursiÃ³n cuando sea posible.  
- Evita copiar grandes estructuras, usa referencias para manejar datos.  
- Procesa los datos en streaming para no cargar todo en memoria.  

#### **Ejemplo:**
Uso de yield para procesamiento en streaming.  
```python
def leer_lineas(archivo):
    with open(archivo, 'r') as f:
        for linea in f:
            yield linea.strip()
```
ğŸ“Œ Complejidad espacial: O(1), ya que solo mantiene una lÃ­nea de texto en memoria a la vez.  

---

### **3ï¸âƒ£ Estructuras de Datos Adecuadas**  
ğŸ”¹ Elegir la estructura de datos correcta reduce la complejidad de las operaciones que realizas en el algoritmo.  

#### ğŸ“Š Tabla: Estructuras de Datos y su Complejidad  

| **Tarea**                  | **Estructura Recomendada**       | **Complejidad** |
|----------------------------|---------------------------------|-----------------|
| **Buscar elemento rÃ¡pido**  | `Hash Table` (`dict`, `HashMap`) | **O(1)**       |
| **Ordenar datos**          | `Heap`, Ãrboles Balanceados      | **O(n log n)**  |
| **Acceder por Ã­ndice**      | `Array`, `Lista`                | **O(1)**       |
| **Insertar en cualquier parte** | `Lista Enlazada`          | **O(1) - O(n)** |
| **Procesar en orden FIFO**  | `Cola` (`Queue`)                | **O(1)**       |
| **Procesar en orden LIFO**  | `Pila` (`Stack`)                | **O(1)**       |

ğŸ“Œ Ejemplo: Si necesitas buscar valores rÃ¡pidamente, usa un **set** o **dict**, ya que la bÃºsqueda es O(1) en lugar de O(n) con listas.  

---

### **4ï¸âƒ£ Evitar Bucles Ineficientes** 
ğŸ”¹ Evita bucles anidados innecesarios (O(nÂ²)) si se puede usar una estructura mÃ¡s eficiente.  
ğŸ”¹ Ejemplo malo:  
```python
# O(nÂ²) - Ineficiente
for i in lista:
    for j in otra_lista:
        if i == j:
            print(i)
```

ğŸ”¹ Ejemplo mejorado (O(n)) con **set**:  
```python
# O(n) - Eficiente
conjunto = set(otra_lista)
for i in lista:
    if i in conjunto:
        print(i)
```
ğŸ“Œ Mejoramos de O(nÂ²) a O(n) usando un set! ğŸš€  

---

### **5ï¸âƒ£ Uso Eficiente de LibrerÃ­as y Paralelismo**  
ğŸ”¹ En Python, usa librerÃ­as optimizadas como **NumPy**, **Pandas**, multiprocessing para acelerar cÃ¡lculos.
ğŸ”¹ En Big Data, usa frameworks distribuidos como **Apache Spark** o **Dask**.
ğŸ”¹ Implementa **paralelismo** y **concurrencia** para procesar datos en varios nÃºcleos de CPU.

#### **âœ” SoluciÃ³n:**
```python
# Uso de multiprocessing en Python para dividir el trabajo
from multiprocessing import Pool

def calcular(x):
    return x * x

datos = [1, 2, 3, 4, 5]
with Pool() as p:
    resultados = p.map(calcular, datos)
print(resultados)
```
ğŸ“Œ Mejora el tiempo de ejecuciÃ³n al usar mÃºltiples nÃºcleos del procesador para realizar cÃ¡lculos en paralelo.  

---

### ğŸ“Š  **Resumen de Factores Claves para un Algoritmo Eficiente**

| **Factor**                          | **Â¿QuÃ© hacer?** |
|--------------------------------------|-----------------|
| **Tiempo de ejecuciÃ³n (`O(f(n))`)**  | Optimiza estructuras de datos, evita bucles innecesarios. |
| **Uso de memoria (`O(f(n))`)**       | Reduce duplicaciones, usa `yield` o `iterables`. |
| **Estructuras adecuadas**            | Usa `set`, `dict`, `heap`, `queue` segÃºn la necesidad. |
| **Bucles eficientes**                | Evita `O(nÂ²)`, usa `set` o `dict` para bÃºsquedas. |
| **Paralelismo**                      | Usa `multiprocessing`, `NumPy`, `Spark` en Big Data. |

ğŸ“Œ Si optimizas estos puntos, tu algoritmo serÃ¡ eficiente y escalable en tÃ©rminos de tiempo y memoria. ğŸš€

---

## ğŸ“ˆ Crecimiento de Diferentes Complejidades  
El crecimiento de la complejidad de un algoritmo describe cÃ³mo aumentan el **tiempo de ejecuciÃ³n** y el **uso de memoria** en funciÃ³n del tamaÃ±o de la entrada (`n`).  
Podemos representar estas **complejidades comunes** con grÃ¡ficos que ilustran su comportamiento.  

---

### ğŸ’¡ Crecimiento de algunas funciones de complejidad comunes
ğŸ”  **ExplicaciÃ³n:**  
- **O(1):** Tiempo constante, no importa el tamaÃ±o de `n`.  
- **O(log n):** Crece lentamente, ejemplo: bÃºsqueda binaria.  
- **O(n):** Crecimiento lineal, ejemplo: recorrido de una lista.  
- **O(n log n):** Crece mÃ¡s rÃ¡pido, pero sigue siendo eficiente, ejemplo: QuickSort.  
- **O(nÂ²):** CuadrÃ¡tico, se vuelve lento con `n` grande, ejemplo: bubble sort.  
- **O(2â¿):** Exponencial, muy ineficiente para valores altos de `n`.  

---

### ğŸ“Š ComparaciÃ³n en Tabla  

| **Complejidad** | **Ejemplo de Algoritmo**    | **Crecimiento** |
|----------------|---------------------------|----------------|
| **O(1)**       | Acceso a un array (`arr[i]`) | Constante |
| **O(log n)**   | BÃºsqueda binaria           | Muy lento |
| **O(n)**       | Recorrer una lista         | Lineal |
| **O(n log n)** | QuickSort, MergeSort       | Cuasi-lineal |
| **O(nÂ²)**      | Bubble Sort, Selection Sort | CuadrÃ¡tico |
| **O(2â¿)**      | Algoritmo de fuerza bruta  | Exponencial |

---

### ğŸ”¢ CÃ³digo en Python para Generar el GrÃ¡fico  
Si deseas generar tu propio grÃ¡fico de crecimiento de complejidad, usa el siguiente cÃ³digo en Python:  
```python
import numpy as np
import matplotlib.pyplot as plt

n = np.linspace(1, 10, 100)

plt.figure(figsize=(8, 6))
plt.plot(n, np.ones_like(n), label="O(1)", linestyle='dashed')
plt.plot(n, np.log2(n), label="O(log n)")
plt.plot(n, n, label="O(n)")
plt.plot(n, n * np.log2(n), label="O(n log n)")
plt.plot(n, n**2, label="O(nÂ²)")
plt.plot(n, 2**n, label="O(2â¿)")

plt.ylim(0, 100)
plt.legend()
plt.xlabel("TamaÃ±o de Entrada (n)")
plt.ylabel("Operaciones")
plt.title("Crecimiento de Complejidad")
plt.show()
```

---

## ğŸ“š Recursos Adicionales  
ğŸ“– [Big-O Cheat Sheet](https://www.bigocheatsheet.com/)  
ğŸ¥ [Video Explicativo en YouTube](https://www.youtube.com/watch?v=__vX2sjlpXU)  
ğŸ“– [CS50 Harvard - IntroducciÃ³n a Algoritmos](https://cs50.harvard.edu/)  
